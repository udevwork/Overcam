import Foundation
import AVFoundation
import Photos
import CoreImage
import Metal
import MetalKit
import SwiftUI

final class NewCameraManager: NSObject, ObservableObject {
    
    private let photoOutput = AVCapturePhotoOutput()
    
    private let session = AVCaptureSession()
    private let videoOutput = AVCaptureVideoDataOutput()
    public var deviceInput: AVCaptureDeviceInput?
    private let ciContext = CIContext()
    private var textureCache: CVMetalTextureCache?
    
    public var availableDevices: [AVCaptureDevice] = []
    
    //@Published var currentPixelBuffer: CVPixelBuffer?
    var onNewPixelBuffer: ((CVPixelBuffer) -> Void)? = nil
    @Published var currentdevice: AVCaptureDevice?
    
    @Published var isRunning = false

    @Published var referenceImage:  CGImage?
    @Published var referenceAlpha: Float = 0.5
    
    @Published var camExpRange: (CMTime,CMTime) = (.zero,.zero)
    
    @Published var lastCapturedImage: UIImage?
    
    
    @Published var zoom:CGFloat = 1.0
    @Published var lastZoomLevel: CGFloat = 1.0
    @Published var flash: Bool = false
    @Published var grid: Bool = false
    @Published var front: Bool = false
    @Published var expBias: Double = 0.005
    @Published var iso: Float = 200.0
    
    override init() {
        super.init()
        setupSession()
    }

    private func setupSession() {
        session.beginConfiguration()
        session.sessionPreset = .photo

        // ĞĞ°Ğ¹Ñ‚Ğ¸ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° (ĞºĞ°Ğ¼ĞµÑ€Ñ‹)
        let discoverySession = AVCaptureDevice.DiscoverySession(
            deviceTypes: [.builtInWideAngleCamera, .builtInUltraWideCamera, .builtInTelephotoCamera],
            mediaType: .video,
            position: .back
        )
        availableDevices = discoverySession.devices

        guard let defaultDevice = availableDevices.first else {
            print("No available cameras!")
            session.commitConfiguration()
            return
        }

        do {
            let input = try AVCaptureDeviceInput(device: defaultDevice)
            if session.canAddInput(input) {
                session.addInput(input)
                deviceInput = input
            }
            self.currentdevice = defaultDevice
        } catch {
            print("Error setting device input: \(error)")
        }

        if session.canAddOutput(videoOutput) {
            videoOutput.setSampleBufferDelegate(self, queue: DispatchQueue(label: "camera.frame.processing"))
            session.addOutput(videoOutput)
            videoOutput.alwaysDiscardsLateVideoFrames = true
            videoOutput.videoSettings = [kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA]
            if let connection = videoOutput.connection(with: .video) {
                if #available(iOS 17.0, *) {
                    connection.videoRotationAngle = 90
                } else if connection.isVideoOrientationSupported {
                    connection.videoOrientation = .portrait
                }
            }
        }

        if session.canAddOutput(photoOutput) {
            session.addOutput(photoOutput)
            photoOutput.isHighResolutionCaptureEnabled = true
        }
        
        self.camExpRange = getExpRange()
        
        session.commitConfiguration()
        
        CVMetalTextureCacheCreate(nil, nil, MTLCreateSystemDefaultDevice()!, nil, &textureCache)
    }
    
    func start() {
        guard !session.isRunning else { return }
        DispatchQueue.global(qos: .background).async {
            self.session.startRunning()
            DispatchQueue.main.async {
                withAnimation {
                    self.isRunning = true
                }
            }
        }
     
    }

    func stop() {
        guard session.isRunning else { return }
        DispatchQueue.main.async {
            withAnimation {
                self.isRunning = false
            }
        }
        DispatchQueue.global(qos: .background).asyncAfter(deadline: .now()+0.35, execute: {
            self.session.stopRunning()
        })
    }

    func switchCamera(to deviceType: AVCaptureDevice.DeviceType) {
        guard let device = availableDevices.first(where: { $0.deviceType == deviceType }) else {
            print("Requested device type not available")
            return
        }

        session.beginConfiguration()
        if let currentInput = deviceInput {
            session.removeInput(currentInput)
        }

        do {
            let newInput = try AVCaptureDeviceInput(device: device)
            if session.canAddInput(newInput) {
                session.addInput(newInput)
                deviceInput = newInput
            }
        } catch {
            print("Error switching cameras: \(error)")
        }

        session.commitConfiguration()
    }

    func captureHighQualityPhoto() {
        let settings = AVCapturePhotoSettings()

//        settings.isHighResolutionPhotoEnabled = true
//        settings.isAutoStillImageStabilizationEnabled = true

        if photoOutput.supportedFlashModes.contains(.auto) {
            settings.flashMode = flash ? .on : .off
        }

        photoOutput.capturePhoto(with: settings, delegate: self)
    }
    

    private func saveImageToPhotos(image: UIImage) {
        PHPhotoLibrary.shared().performChanges({
            let request = PHAssetCreationRequest.forAsset()
            if let data = image.heicData() {
                request.addResource(with: .photo, data: data, options: nil)
            } else if let jpegData = image.jpegData(compressionQuality: 0.9) {
                request.addResource(with: .photo, data: jpegData, options: nil)
            }
        }, completionHandler: { success, error in
            if success {
                print("Saved photo to library!")
            } else {
                print("Error saving photo: \(String(describing: error))")
            }
        })
    }
}

extension NewCameraManager: AVCaptureVideoDataOutputSampleBufferDelegate {
    public func captureOutput(_ output: AVCaptureOutput, didOutput sampleBuffer: CMSampleBuffer, from connection: AVCaptureConnection) {
        guard let pixelBuffer = CMSampleBufferGetImageBuffer(sampleBuffer) else { return }
        onNewPixelBuffer?(pixelBuffer)
    }
}

extension NewCameraManager: AVCapturePhotoCaptureDelegate {
    func photoOutput(_ output: AVCapturePhotoOutput,
                     didFinishProcessingPhoto photo: AVCapturePhoto,
                     error: Error?) {
        if let error = error {
            print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Ğµ Ñ„Ğ¾Ñ‚Ğ¾: \(error)")
            return
        }
        
        guard let data = photo.fileDataRepresentation() else {
            print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ„Ğ¾Ñ‚Ğ¾")
            return
        }
        
        PHPhotoLibrary.shared().performChanges {
            let request = PHAssetCreationRequest.forAsset()
            request.addResource(with: .photo, data: data, options: nil)
            
        } completionHandler: { success, error in
            if success {
                print("âœ… Ğ¤Ğ¾Ñ‚Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ² Ğ³Ğ°Ğ»ĞµÑ€ĞµÑ!")
                if let fullImage = UIImage(data: data) {
                    let thumbnail = fullImage.preparingThumbnail(of: CGSize(width: 80, height: 80))
                    DispatchQueue.main.async {
                        withAnimation {
                            self.lastCapturedImage = thumbnail
                        }
                    }
                }
                haptic()
            } else {
                print("âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸ Ñ„Ğ¾Ñ‚Ğ¾: \(String(describing: error))")
            }
        }
    }
}

extension AVCaptureDevice {
    /// Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ½Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ·ÑƒĞ¼-Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ² Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğµ (0.5, 1.0, 2.0 Ğ¸ Ñ‚.Ğ´.)
    var nominalZoom: Float {
        switch deviceType {
        case .builtInUltraWideCamera:
            return 0.5
        case .builtInWideAngleCamera:
            return 1.0
        case .builtInTelephotoCamera:
            return 2.0 // ĞœĞ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ¸ 3.0, Ğ½Ğ¾ Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° â€” 2.0 Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
        default:
            return 1.0
        }
    }
}

// MARK: - Helper

import UniformTypeIdentifiers
import UIKit

extension UIImage {
    func heicData() -> Data? {
        let options: [CFString: Any] = [kCGImageDestinationLossyCompressionQuality: 0.9]
        let data = NSMutableData()
        guard let destination = CGImageDestinationCreateWithData(data, AVFileType.heic as CFString, 1, nil) else { return nil }
        if let cgImage = self.cgImage {
            CGImageDestinationAddImage(destination, cgImage, options as CFDictionary)
            guard CGImageDestinationFinalize(destination) else { return nil }
            return data as Data
        }
        return nil
    }
}

// MARK: - ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ĞºĞ°Ğ¼ĞµÑ€Ñ‹

extension NewCameraManager {
    
    func setZoom() {
        guard let device = deviceInput?.device else { return }

        let maxZoom = min(device.activeFormat.videoMaxZoomFactor, 6.0) // 6x â€” Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸
        let minZoom: CGFloat = 1.0

        let clamped = max(min(zoom, maxZoom), minZoom)

        do {
            try device.lockForConfiguration()
            device.videoZoomFactor = clamped
            device.unlockForConfiguration()
        } catch {
            print("âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ğ·ÑƒĞ¼: \(error)")
        }
    }
    
    func setTorch(active: Bool) {
        guard let device = deviceInput?.device,
              device.hasTorch, device.isTorchAvailable else {
            print("âŒ Torch not available on this device")
            return
        }

        do {
            try device.lockForConfiguration()

            if active {
                try device.setTorchModeOn(level: 1.0) // Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ ÑÑ€ĞºĞ¾ÑÑ‚Ğ¸
            } else {
                device.torchMode = .off
            }

            device.unlockForConfiguration()
        } catch {
            print("âŒ Torch configuration failed: \(error)")
        }
    }
    
    func switchToFrontCamera() {
        guard let frontCamera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .front) else {
            print("âŒ Ğ¤Ñ€Ğ¾Ğ½Ñ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ ĞºĞ°Ğ¼ĞµÑ€Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
            return
        }

        switchCamera(to: frontCamera)
    }
    
    func switchToBackCamera() {
        guard let backCamera = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            print("âŒ ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ ĞºĞ°Ğ¼ĞµÑ€Ğ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°")
            return
        }

        switchCamera(to: backCamera)
    }
    
    func switchCamera(to newDevice: AVCaptureDevice) {
        session.beginConfiguration()

        if let currentInput = deviceInput {
            session.removeInput(currentInput)
        }

        do {
            let newInput = try AVCaptureDeviceInput(device: newDevice)
            
            if session.canAddInput(newInput) {
                session.addInput(newInput)
                deviceInput = newInput
                currentdevice = newDevice
            } else {
                print("âš ï¸ Cannot add new camera input")
            }
        } catch {
            print("âš ï¸ Failed to create input: \(error)")
        }

        // ĞĞµ Ğ·Ğ°Ğ±ÑƒĞ´ÑŒ Ğ²Ñ‹ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¾Ñ€Ğ¸ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞ¼ĞµĞ½Ñ‹ ĞºĞ°Ğ¼ĞµÑ€Ñ‹
        if let connection = videoOutput.connection(with: .video) {
            if #available(iOS 17.0, *) {
                connection.videoRotationAngle = 90
            } else if connection.isVideoOrientationSupported {
                connection.videoOrientation = .portrait
            }
        }

        session.commitConfiguration()
    }
    
    
    func setCustomExposure() {
        guard let device = deviceInput?.device else { return }

        let format = device.activeFormat
        let minDuration = format.minExposureDuration
        let maxDuration = format.maxExposureDuration
        let clampedDuration = min(max(expBias.asCMTime, minDuration), maxDuration)

        let minISO = format.minISO
        let maxISO = format.maxISO
        let clampedISO = min(max(iso, minISO), maxISO)

        do {
            try device.lockForConfiguration()

            if device.isExposureModeSupported(.custom) {
                device.setExposureModeCustom(duration: clampedDuration, iso: clampedISO, completionHandler: nil)
                print("ğŸ“¸ Exposure set: \(CMTimeGetSeconds(clampedDuration))s @ ISO \(clampedISO) (range: \(minISO)â€“\(maxISO))")
            }

            device.unlockForConfiguration()
        } catch {
            print("âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ: \(error)")
        }
    }

    
    func getExpRange() -> (CMTime,CMTime){
        guard let device = deviceInput?.device else { return (.zero,.zero) }
        let range = (device.activeFormat.minExposureDuration,
        device.activeFormat.maxExposureDuration)
        return range
    }
    
    func setAutoExposure() {
        guard let device = deviceInput?.device else { return }

        do {
            try device.lockForConfiguration()

            if device.isExposureModeSupported(.continuousAutoExposure) {
                device.exposureMode = .continuousAutoExposure
            }

            device.unlockForConfiguration()
        } catch {
            print("âš¡ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾ÑĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ: \(error)")
        }
    }
    
    func focus(at point: CGPoint, viewSize: CGSize) {
        guard let device = deviceInput?.device else { return }

          do {
              try device.lockForConfiguration()

              let normalizedPoint = CGPoint(x: point.y / viewSize.height, y: 1.0 - point.x / viewSize.width)

              if device.isFocusPointOfInterestSupported {
                  device.focusPointOfInterest = normalizedPoint
                  device.focusMode = .autoFocus
              }

              if device.isExposurePointOfInterestSupported {
                  device.exposurePointOfInterest = normalizedPoint
                  device.exposureMode = .continuousAutoExposure
              }

              device.unlockForConfiguration()
          } catch {
              print("âš¡ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ñ„Ğ¾ĞºÑƒÑĞ°/ÑĞºÑĞ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸: \(error)")
          }
    }
    
}

extension CMTime {
    var asSeconds: Double {
        return CMTimeGetSeconds(self)
    }
}

extension Double {
    var asCMTime: CMTime {
        CMTimeMakeWithSeconds(self, preferredTimescale: 1_000_000_000)
    }
}

extension Double {
    var asExposureString: String {
        if self >= 1.0 {
            return String(format: "%.1fs", self)
        } else if self > 0 {
            let denominator = Int((1.0 / self).rounded())
            return "1/\(denominator)s"
        } else {
            return "0s"
        }
    }
}
